> This repo is about a series of references which are written in AI-related conference or journal.
> I wrote below contents based on the [one]((https://arxiv.org/pdf/2406.20095v1)) of VLA papers accepted in ICLR 2025.

# URL

1. OpenAI. New models and developer products announced at devday, 2023.
URL https://openai.com/blog/new-models-and-developer-products-announced-at-devday

2. OpenAI. Hello gpt-4o: We’re announcing gpt-4o, our new flagship model that can reason
across audio, vision, and text in real time., 2024. URL https://openai.com/index/
hello-gpt-4o/.

3. OpenAI. GPT-4 technical report. https://arxiv.org/abs/2303.08774, 2023.
   
4. Meta AI. Llama 3, 2024. URL https://llama.meta.com/llama3/. Accessed: 2024-06-24.

5. Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,
Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An
open-source chatbot impressing gpt-4 with 90%* chatgpt quality, **March 2023**. URL https:
//lmsys.org/blog/2023-03-30-vicuna/.

# arXiv

1. Yuval Alaluf, Daniel Garibi, Or Patashnik, Hadar Averbuch-Elor, and Daniel Cohen-Or. Cross-image
attention for zero-shot appearance transfer. arXiv preprint arXiv:2311.03335, 2023.

: Authors, Title, arXiv, Year.

### Publications with the same 1st author(not the only one)

Focus on year citation format (i.e., 2023a, 2023b, and 2023c).

2-1. Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi Chen, Krzysztof Choromanski, Tianli Ding, Danny Driess, Avinava Dubey, Chelsea Finn, et al. Rt-2: Vision-language-action models transfer web knowledge to robotic control. arXiv preprint arXiv:2307.15818, **2023a**.

2-2. Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis, Chelsea Finn,
Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Jasmine Hsu, Julian Ibarz, Brian
Ichter, Alex Irpan, Tomas Jackson, Sally Jesmonth, Nikhil J Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Isabel Leal, Kuang-Huei Lee, Sergey Levine, Yao Lu, Utsav Malla, Deeksha Manjunath, Igor Mordatch, Ofir Nachum, Carolina Parada, Jodilyn Peralta, Emily Perez, Karl
Pertsch, Jornell Quiambao, Kanishka Rao, Michael S. Ryoo, Grecia Salazar, Pannag Sanketi,
Kevin Sayed, Jaspiar Singh, Sumedh Sontakke, Austin Stone, Clayton Tan, Huong Tran, Vincent
Vanhoucke, Steve Vega, Quan Vuong, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, Tianhe Yu, and
Brianna Zitkovich. Rt-1: Robotics transformer for real-world control at scale. Robotics science
and systems (RSS), **2023b**.

2-3. Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander Herzog, Daniel Ho,
Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, et al. Do as i can, not as i say: Grounding
language in robotic affordances. In Conference on Robot Learning (CoRL), pp. 287–318. **PMLR**,
**2023c**.

: PMLR is one of publisher

3. Same last name, but different first name

3-1. **Jiaxing Huang**, Jingyi Zhang, Kai Jiang, Han Qiu, and Shijian Lu. Visual instruction tuning towards
general-purpose multimodal model: A survey. arXiv preprint arXiv:2312.16602, **2023a**.

3-2. **Wenlong Huang**, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun Wu, and Li Fei-Fei. Voxposer:
Composable 3d value maps for robotic manipulation with language models. arXiv preprint
arXiv:2307.05973, **2023b**.

# Conference

## CVPR

Gwangbin Bae and Andrew J. Davison. Rethinking inductive biases for surface normal estimation.
In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024.

: Authors, Title, CVPR, Year.

Mu Cai, Haotian Liu, Dennis Park, Siva Karthik Mustikovela, Gregory P. Meyer, Yuning Chai, and
Yong Jae Lee. Vip-llava: Making large multimodal models understand arbitrary visual prompts. **In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)**,
2024.

: Authors, Title, Proceedings_full_name (CVPR), Year.

## ICCV

Carl Doersch, Abhinav Gupta, and Alexei A Efros. Unsupervised visual representation learning by
context prediction. **In Proceedings of the International Conference on Computer Vision (ICCV)**,
pp. 1422–1430, 2015.

## NeurIPS

Yining Hong, Haoyu Zhen, Peihao Chen, Shuhong Zheng, Yilun Du, Zhenfang Chen, and Chuang Gan.
3d-llm: Injecting the 3d world into large language models. In Advances in Neural Information Processing Systems (NeurIPS), 2023.

Xiang Li, Jinghuan Shang, Srijan Das, and Michael S. Ryoo. Does self-supervised learning really improve reinforcement learning from pixels? **In Advances in Neural Information Processing Systems (NeurIPS), volume 35, pp. 30865–30881**, 2022.

## ICML

Yunfan Jiang, Agrim Gupta, Zichen Zhang, Guanzhi Wang, Yongqiang Dou, Yanjun Chen, Li FeiFei, Anima Anandkumar, Yuke Zhu, and Linxi Fan. Vima: General robot manipulation with multimodal prompts. **In Proceedings of the International Conference on Machine Learning (ICML)**, 2023.

## ICRA

Lerrel Pinto and Abhinav Gupta. Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours. **In IEEE International Conference on Robotics and Automation (ICRA), pp.3406–3413. IEEE**, 2016.

## ECCV

Jinghuan Shang, Kumara Kahatapitiya, Xiang Li, and Michael S. Ryoo. Starformer: Transformer with state-action-reward representations for visual reinforcement learning. **In Proceedings of the European Conference on Computer Vision (ECCV), pp. 462–479. Springer**, 2022a.

## AAAI

Denis Yarats, Amy Zhang, Ilya Kostrikov, Brandon Amos, Joelle Pineau, and Rob Fergus. Improving sample efficiency in model-free reinforcement learning from images. **In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), pp. 10674–10681**, 2021.

# Journal

## TMLR

Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander Novikov,
Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, Tom
Eccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell,
Oriol Vinyals, Mahyar Bordbar, and Freitas de Nando. A generalist agent. **In Trans. on Machine
Learning Research**, 2022.

## TPAMI

Jinghuan Shang, Xiang Li, Kumara Kahatapitiya, Yu-Cheol Lee, and Michael S. Ryoo. Starformer:
Transformer with state-action-reward representations for robot learning. **IEEE Transactions on
Pattern Analysis and Machine Intelligence, pp. 1–16**, 2022b.


